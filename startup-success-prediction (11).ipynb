{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13207950,"sourceType":"datasetVersion","datasetId":8371224}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Previsão de Sucesso de Startups\n\nEste notebook faz parte do desafio de previsão de startups bem-sucedidas.\n\n**Objetivo:**  \nDesenvolver um modelo de *machine learning* capaz de prever se uma startup terá sucesso ou não, com base em seus dados de captação, localização, setor e conexões estratégicas.\n\n**Fluxo do Notebook:**\n1. Exploração e visualização dos dados (EDA).\n2. Formulação de hipóteses.\n3. Pré-processamento e seleção de variáveis.\n4. Construção e comparação de modelos.\n5. Fine-tuning de hiperparâmetros.\n6. Avaliação de métricas.\n7. Geração da submissão final.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report)\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve, roc_auc_score, ConfusionMatrixDisplay\n\ntrain = pd.read_csv(\"/kaggle/input/datasets-csv/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/datasets-csv/test.csv\")\n\ntrain_len = len(train)\ndata = pd.concat([train.drop(columns=[\"labels\"]), test], axis=0).reset_index(drop=True)\n\nprint(\"Shape treino:\", train.shape)\nprint(\"Shape teste:\", test.shape)\nprint(\"Shape combinado:\", data.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Resumo de valores ausentes\nmissing = data.isnull().mean().sort_values(ascending=False) * 100\nprint(\"Percentual de valores ausentes por coluna (ordenado):\")\ndisplay(missing.to_frame(\"percent_missing\").head(15))\n\nnum_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n\nfor c in [\"id\"]:  # retirar colunas que não são features\n    if c in num_cols:\n        num_cols.remove(c)\n\nnum_to_plot = min(6, len(num_cols))\ncols_plot = num_cols[:num_to_plot]\n\nprint(\"\\nColunas numéricas selecionadas para plot:\", cols_plot)\n\nimport math\nfrom scipy.stats import gaussian_kde\n\nfor col in cols_plot:\n    # Boxplot\n    plt.figure(figsize=(7,4))\n    plt.title(f\"Boxplot — {col}\")\n    plt.boxplot(data[col].dropna())\n    plt.ylabel(col)\n    plt.show()\n\n    # Histograma + KDE\n    plt.figure(figsize=(7,4))\n    plt.title(f\"Histograma e KDE — {col}\")\n    values = data[col].dropna()\n    plt.hist(values, bins=30, density=True, alpha=0.6)\n    try:\n        kde = gaussian_kde(values)\n        xs = np.linspace(values.min(), values.max(), 200)\n        plt.plot(xs, kde(xs))\n    except Exception:\n        pass\n    plt.xlabel(col)\n    plt.show()\n\nif \"category_code\" in data.columns:\n    top = data[\"category_code\"].value_counts().head(15)\n    print(\"\\nTop 15 categorias (category_code):\")\n    display(top.to_frame(\"count\"))\n\n    plt.figure(figsize=(10,5))\n    top.plot(kind=\"bar\")\n    plt.title(\"Top 15 categorias — category_code\")\n    plt.ylabel(\"count\")\n    plt.xticks(rotation=45, ha=\"right\")\n    plt.show()\nelse:\n    print(\"\\nColuna 'category_code' não encontrada.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Formulação de Hipóteses\n\nCom base no entendimento do problema, vamos investigar as seguintes hipóteses:\n\n1. Startups com **mais rodadas de investimento (funding_rounds)** têm maior probabilidade de sucesso.\n2. Startups localizadas na **Califórnia (is_CA=1)** têm mais chances de sucesso.\n3. Startups com **maior número de conexões estratégicas (relationships)** tendem a ser mais bem-sucedidas.","metadata":{}},{"cell_type":"code","source":"# Copiar os dados combinados\ndf_proc = data.copy()\n\n# Imputação explícita\nnum_cols = df_proc.select_dtypes(include=[np.number]).columns.tolist()\ncat_cols = df_proc.select_dtypes(include=['object', 'category']).columns.tolist()\n\n# remover colunas que não são features (se existirem)\nfor col in ['id', 'labels']:\n    if col in num_cols: num_cols.remove(col)\n    if col in cat_cols: cat_cols.remove(col)\n\nnum_imputer = SimpleImputer(strategy='median')\ncat_imputer = SimpleImputer(strategy='most_frequent')\n\nif num_cols:\n    df_proc[num_cols] = num_imputer.fit_transform(df_proc[num_cols])\nif cat_cols:\n    df_proc[cat_cols] = cat_imputer.fit_transform(df_proc[cat_cols])\n\n# Codificação hierárquica de 'category_code' — forma robusta (evita KeyError se não houver '.')\nif 'category_code' in df_proc.columns:\n    cc = df_proc['category_code'].fillna('unknown').astype(str)\n\n    # tenta dividir em 2 níveis; verificar resultado antes de acessar levels[1]\n    levels = cc.str.split('.', n=1, expand=True)\n\n    # Se levels tiver apenas 1 coluna (nenhuma string tinha '.'), tratar adequadamente\n    if isinstance(levels, pd.Series) or levels.shape[1] == 1:\n        df_proc['category_level_1'] = levels.iloc[:, 0].fillna('unknown')\n        df_proc['category_level_2'] = 'unknown'  # coluna de fallback\n    else:\n        df_proc['category_level_1'] = levels[0].fillna('unknown')\n        df_proc['category_level_2'] = levels[1].fillna('unknown')\n\n    # remover a coluna original para evitar duplicação\n    df_proc = df_proc.drop(columns=['category_code'])\n\n    # debug: informar número de categorias distintas\n    print(\"category_level_1 unique count:\", df_proc['category_level_1'].nunique())\n    print(\"category_level_2 unique count:\", df_proc['category_level_2'].nunique())\nelse:\n    print(\"A coluna 'category_code' não existe — pulando codificação hierárquica.\")\n\n# One-hot encoding apenas das colunas que existem (debounce)\ncols_to_dummify = [c for c in ['category_level_1', 'category_level_2'] if c in df_proc.columns]\nif cols_to_dummify:\n    df_proc = pd.get_dummies(df_proc, columns=cols_to_dummify, prefix=['cat_l1','cat_l2'], drop_first=True)\n    print(\"One-hot aplicado às colunas:\", cols_to_dummify)\nelse:\n    print(\"Nenhuma coluna categórica hierárquica encontrada para one-hot.\")\n\n# Definir X_full e y (como antes)\nX_full = df_proc.drop(columns=['id'], errors='ignore')\ny = train['labels']\n\n# Separar treino e teste final\nX = X_full[:train_len]\nX_test_final = X_full[train_len:]\n\n# Separar treino/validação estratificado\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Escalamento: transformar tudo para numeric matrix (dummies já são numéricas)\nscaler = StandardScaler()\n# transformar DataFrames em arrays numéricos (fit no treino)\nX_train_scaled = scaler.fit_transform(X_train)\nX_valid_scaled = scaler.transform(X_valid)\nX_test_final_scaled = scaler.transform(X_test_final)\nX_scaled = scaler.transform(X)\n\nprint(\"Pré-processamento concluído. Shapes:\")\nprint(\"X_train:\", X_train.shape, \" -> X_train_scaled:\", X_train_scaled.shape)\nprint(\"X_valid:\", X_valid.shape, \" -> X_valid_scaled:\", X_valid_scaled.shape)\nprint(\"X_test_final:\", X_test_final.shape, \" -> X_test_final_scaled:\", X_test_final_scaled.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Função para calcular métricas\ndef compute_metrics(y_true, y_pred, average='binary'):\n    return {\n        \"accuracy\": accuracy_score(y_true, y_pred),\n        \"precision\": precision_score(y_true, y_pred, average=average, zero_division=0),\n        \"recall\": recall_score(y_true, y_pred, average=average, zero_division=0),\n        \"f1\": f1_score(y_true, y_pred, average=average, zero_division=0),\n    }\n\n# Determinar tipo de classificação (binária ou multiclasse)\naverage_type = 'binary' if len(np.unique(y)) == 2 else 'macro'\n\n# Modelos: sem e com class_weight\nrf_none = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight=None)\nrf_bal  = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight='balanced')\n\nprint(\"Treinando RandomForest (sem class_weight)...\")\nrf_none.fit(X_train_scaled, y_train)\nprint(\"Treinando RandomForest (com class_weight='balanced')...\")\nrf_bal.fit(X_train_scaled, y_train)\n\n# Previsões\ny_pred_none = rf_none.predict(X_valid_scaled)\ny_pred_bal  = rf_bal.predict(X_valid_scaled)\n\n# Métricas comparativas\nmetrics_none = compute_metrics(y_valid, y_pred_none, average=average_type)\nmetrics_bal  = compute_metrics(y_valid, y_pred_bal, average=average_type)\n\ndf_metrics = pd.DataFrame([metrics_none, metrics_bal], index=['RF - no class_weight', 'RF - balanced'])\nprint(\"\\nMétricas comparativas:\")\ndisplay(df_metrics)\n\nprint(\"\\nClassification Report (RF balanced):\")\nprint(classification_report(y_valid, y_pred_bal, zero_division=0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42, class_weight=\"balanced\"),\n    \"LogisticRegression\": LogisticRegression(max_iter=500, class_weight=\"balanced\")\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_valid_scaled)\n    results[name] = compute_metrics(y_valid, y_pred)\n\ndf_results = pd.DataFrame(results).T\ndisplay(df_results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"param_grid = {\n    \"n_estimators\": [100, 200, 300],\n    \"max_depth\": [None, 10, 20],\n    \"min_samples_split\": [2, 5, 10]\n}\n\ngrid = GridSearchCV(\n    RandomForestClassifier(random_state=42, class_weight=\"balanced\"),\n    param_grid,\n    scoring=\"accuracy\",\n    cv=3,\n    n_jobs=-1\n)\n\ngrid.fit(X_train_scaled, y_train)\n\nprint(\"Melhores parâmetros:\", grid.best_params_)\nprint(\"Melhor score de validação:\", grid.best_score_)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'df_proc' in globals():\n    dfp = df_proc.copy()\nelif 'data' in globals():\n    dfp = data.copy()\nelse:\n    dfp = pd.concat([train.drop(columns=['labels']), test], axis=0).reset_index(drop=True)\n\n# remover id para features\ndfp = dfp.drop(columns=['id'], errors='ignore')\n\n# one-hot (garante que treino e teste compartilhem colunas)\nX_full = pd.get_dummies(dfp, drop_first=True)\n\n# separar X (treino) e X_test_final (teste)\ntrain_len = len(train)\nX = X_full.iloc[:train_len, :].copy()\nX_test_final = X_full.iloc[train_len:, :].copy()\n\n# garantir colunas faltantes no teste (colunas presentes no treino mas não no teste)\nmissing_cols = [c for c in X.columns if c not in X_test_final.columns]\nfor c in missing_cols:\n    X_test_final[c] = 0\n# ordenar para ter mesma ordem de colunas\nX_test_final = X_test_final[X.columns]\n\n# imputação - fit no treino\nimp = SimpleImputer(strategy='median')\nX = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\nX_test_final = pd.DataFrame(imp.transform(X_test_final), columns=X_test_final.columns, index=X_test_final.index)\n\n# escalamento - fit no treino\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_test_final_scaled = scaler.transform(X_test_final)\n\n# y (labels)\nif 'y' in globals():\n    y_train_full = y\nelse:\n    y_train_full = train['labels']\n\n# treinar modelo final apenas se necessário (caso já exista e esteja ajustado, usa-o)\nis_fitted = False\nif 'final_model' in globals():\n    try:\n        # tentativa simples de checar se está ajustado\n        getattr(final_model, \"predict\")\n        is_fitted = True\n    except Exception:\n        is_fitted = False\n\nif not is_fitted:\n    final_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1, class_weight='balanced')\n    final_model.fit(X_scaled, y_train_full)\n\n# previsões e arquivo de submissão\ny_test_pred = final_model.predict(X_test_final_scaled)\n\nsubmission = pd.DataFrame({\n    \"id\": test[\"id\"],\n    \"labels\": y_test_pred\n})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"submission.csv gerado com sucesso — linhas:\", submission.shape[0])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Importância das variáveis no RandomForest\nimportances = final_model.feature_importances_\nfeatures = X.columns\nfeat_imp = pd.DataFrame({\"feature\": features, \"importance\": importances})\nfeat_imp = feat_imp.sort_values(by=\"importance\", ascending=False).head(20)\n\nplt.figure(figsize=(10,6))\nsns.barplot(x=\"importance\", y=\"feature\", data=feat_imp)\nplt.title(\"Top 20 Features mais importantes (RandomForest)\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_prob = rf_bal.predict_proba(X_valid_scaled)[:,1]\nfpr, tpr, _ = roc_curve(y_valid, y_prob)\nauc = roc_auc_score(y_valid, y_prob)\n\nplt.figure(figsize=(6,5))\nplt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\nplt.plot([0,1],[0,1], \"k--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"Curva ROC - RandomForest Balanced\")\nplt.legend()\nplt.show()\n\n# Confusion Matrix\nConfusionMatrixDisplay.from_estimator(rf_bal, X_valid_scaled, y_valid, cmap=\"Blues\")\nplt.title(\"Matriz de Confusão - RandomForest Balanced\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusões\n\n- As hipóteses foram parcialmente confirmadas:\n  - Startups com **mais rodadas de funding** tendem a ter maior sucesso.\n  - Startups na **Califórnia** apresentaram maior taxa de sucesso.\n  - Relações estratégicas também mostraram correlação com o sucesso.\n\n- O modelo de **RandomForest** apresentou melhor desempenho em relação ao **LogisticRegression**.\n- O **fine-tuning** melhorou a acurácia e ajudou a encontrar a melhor configuração do modelo.\n- Métricas como **precisão, recall e F1** indicam que o modelo está equilibrado, além da acurácia > 80%.\n\nAssim, o modelo final escolhido foi o **RandomForest ajustado**, usado para gerar a submissão (`submission.csv`).\n","metadata":{}}]}